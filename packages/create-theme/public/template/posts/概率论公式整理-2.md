---
title: 概率论公式整理-2
date: 2023-12-22 12:28:29
tags:
  - 概率论与数理统计
---

# 🎈第四章 随机变量的数字特征

## 数学期望

设$  X  $是离散型随机变量,其分布律为

$P\left\{X=x_{i}\right\}=p_{i}, \quad i=1,2,3 \ldots .$

若$  \sum_{i=1}^{+\infty}\left|\boldsymbol{x}_{\boldsymbol{i}}\right| \boldsymbol{p}_{\boldsymbol{i}}<+\infty  $则称

$  E(X)=\sum_{i=1}^{+\infty} x_{i} p_{i}  $为$  X  $的数学期望（均值）。

设连续型随机变量$  X  $的概率密度为$  f(x)  $，
若 

$ \int_{-\infty}^{+\infty}|x| f(x) d x<+\infty $

称$ E(X)=\int_{-\infty}^{+\infty} x f(x) d x $为$  X  $的数学期望(均值)。

> 随机变量的数学期望是它所有可能取值的加权平均值，**是一个数**。
>
> 部分随机变量$  X  $的数学期望不存在。定义中要求条件无穷级数
>
> $\sum_{i=1}^{\infty} x_{i} p_{i}$
>
> 绝对收敛, 保证数学期望有唯一的数值。如果绝对收敛不能得到满足, 称随机变量的数学期望不存在。

###  常用期望

- 两点分布：$E(X)=p$
- $X\sim B(n,p)$：$E(X)=np$
- $X\sim P(\lambda)$：$E(X)=\lambda$
- 均匀分布：$E(X)=(a+b)/2$
- 指数分布：$E(X)=\lambda^{-1}$
- 正态分布：$E(X)=\mu$

### 随机变量的函数的数学期望

（本章核心）设$  Y  $是随机变量$  X  $的函数$  Y=g(X) ,  g(x)  $为连续函数
1. $X  $是离散型随机变量，分布律为

   $\boldsymbol{P}\left\{X=\boldsymbol{x}_{i}\right\}=\boldsymbol{p}_{i}, \quad \boldsymbol{i}=1,2,3 \ldots .$

​	若$  \sum_{i=1}^{+\infty} g\left(x_{i}\right) p_{i}  $绝对收敛，则有

​	$E(Y)=E[g(X)]=\sum_{i=1}^{+\infty} g\left(x_{i}\right) p_{i}$

2. $X  $是连续型随机变量，其概率密度为$  f_{X}(x) $。

   若$  \int_{-\infty}^{+\infty} g(x) \mid f(x)<+\infty  $

   则$  E(Y)=E[g(X)]=\int_{-\infty}^{+\infty} g(x) f_{X}(x) d x $

设$  (X, Y)  $是二维随机变量, 如果$  Z=G(X, Y)  $也是同类型随机变量并且数学期望存在, 则有

- 当$  (X, Y)  $是离散型随机变量时 

​	$E(Z)=\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} G\left(x_{i}, y_{j}\right) p_{i j}$

- 当$  (X, Y)  $是连续型随机变量时

​	$E(Z)=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} G(x, y) f(x, y) d x d y$

### 随机变量的数学期望的性质

设$X,X_1,X_2,\cdots,X_n$是随机变量，$c,b$是常数

- $E(c)=c$

- $E(cX)=cE(X)$

  - $E(cX+b)=cE(X)+b$

- $E\left(\sum_{i=1}^{n} X_{i}\right)=\sum_{i=1}^{n} E\left(X_{i}\right)$

- 若$  X_{1}, X_{2}, \ldots ., X_{n}  $相互独立，则

  $E\left(\prod_{i=1}^{n} X_{i}\right)=\prod_{i=1}^{n} E\left(X_{i}\right)$

## 方差

设$  X  $是随机变量，若$  E\left\{[X-E(X)]^{2}\right\} $存在，称

$D(X)=E\left\{[X-E(X)]^{2}\right\}$


为$  X  $的方差。$ \sigma(X)=\sqrt{D(X)}  $称为$  X  $的标准差或均方差.

> - $D(X) \geq 0 $
>
> - $D(X)  $是随机变量$  X  $的函数的数学期望；当$  X  为$离散型或连续型时，分别有
>
>   $D(X)=\sum_{i=1}^{+\infty}\left[x_{i}-E(X)\right]^{2} P\left\{X=x_{i}\right\},$
>
>   $D(X)=\int_{-\infty}^{+\infty}[x-E(X)]^{2} f_{X}(x) d x$

常用计算公式：

$D(X)=E\left(X^{2}\right)-[E(X)]^{2}$

### 常用方差

- $X\sim B(n,p)$
  - $E(X)=np$
  - $D(X)=np(1-p)$
- $X\sim P(\lambda)$
  - $E(X)=\lambda$
  - $D(X)=\lambda$
- $X\sim N(\mu,\sigma^2)$
  - $E(X)=\mu$
  - $D(X)=\sigma^2$
- 均匀分布
  - $E(X)=(a+b)/2$
  - $D(X)=(b-a)^2/12$
- 指数分布
  - $E(X)=\sqrt{D(X)}=\frac 1\lambda$
  - $D(X)=\frac 1{\lambda^2}$
- $X\sim N(\mu,\sigma^2)$
  - $E(X)=\mu$
  - $D(X)=\sigma^2$

### 随机变量方差的性质

设$X,X_1,X_2,\cdots,X_n$是随机变量，$c,b$是常数

- $E(c)=c,D(c)=0$

- $E(cX)=cE(X),D(cX)=c^2D(X)$

- $E(\sum_{i=1}^n)=\sum_{i=1}^nE(X_i)$

  $D\left(\sum_{i=1}^{n} X_{i}\right)=\sum_{i=1}^{n} D\left(X_{i}\right)+2 \sum_{\substack{i=1 \\ j>i}}^{n} E\left\{\left[X_{i}-E\left(X_{i}\right)\right]\left[X_{j}-E\left(X_{j}\right)\right]\right\}$

​	若$X_1,X_2,\cdots,X_n$**相互独立**，则

​	$\begin{array}{l}
E\left(\prod_{i=1}^{n} X_{i}\right)=\prod_{i=1}^{n} E\left(X_{i}\right) \\
D\left(\sum_{i=1}^{n} X_{i}\right)=\sum_{i=1}^{n} D\left(X_{i}\right)
\end{array}$

- $D(X)=0\longleftrightarrow P\{X=E(X)\}=1$

- 方差刻划了随机变量$ X $围绕其数学期望的偏离程度
- 方差是随机变量$ X $关于任何值的偏离程度的最小值

## 协方差&相关系数&矩

### 协方差

若$  E\{[X-E(X)][Y-E(Y)]\}  $存在，称

$\operatorname{Cov}(X, Y)=E\{[X-E(X)][Y-E(Y)]\}$


为随机变量$  (X, Y)  $的协方差.

$D(X \pm Y)=D(X)+D(Y) \pm 2 \operatorname{Cov}(X, Y)$

#### 性质

1.  $D(X)=\operatorname{Cov}(X, X) $
2.  $\operatorname{Cov}(X, Y)=\operatorname{Cov}(Y, X) $
3.  $\operatorname{Cov}(a X, b Y)=a b \operatorname{Cov}(X, Y), a, b  $是常数;

4.  $\operatorname{Cov}(X, a)=0 $
5.  $\operatorname{Cov}\left(X_{1}+X_{2}, Y\right)=\operatorname{Cov}\left(X_{1}, Y\right)+\operatorname{Cov}\left(X_{2}, Y\right) $
6.  $X, Y  $相互独立，$ \operatorname{Cov}(X, Y)=0 $

常用计算公式：$Cov(X,Y)=E(XY)-E(X)E(Y)$

### 相关系数

设二维随机变量$  X, Y  $的$  D(X)>0 ,  D(Y)>0 $，称

$\rho_{X Y}=\frac{\operatorname{Cov}(X, Y)}{\sqrt{D(X)} \sqrt{D(Y)}}$

为随机变量  X  与  Y  的相关系数.

- $\rho_{X Y} $是一无量纲的量

- 标准化随机变量的协方差：

  $\begin{aligned}
  \rho_{X Y} & =E\left[\frac{X-E(X)}{\sqrt{D(X)}} \cdot \frac{Y-E(Y)}{\sqrt{D(Y)}}\right] \\
  & =E\left[X^{*} Y^{*}\right]=\operatorname{Cov}\left(X^{*}, Y^{*}\right)
  \end{aligned}$

#### 性质

设随机变量$X,Y$的相关系数$\rho$存在，则

- $|\rho|\leq1$

- $|\rho|=1\longleftrightarrow X$与$Y$以概率为1线性相关，即

  存在$  \alpha, \beta,(\alpha \neq 0) $,

  $P\{Y=\alpha X+\beta\}=1$

- 若$  \xi=a_{1} X+b_{1}, \eta=a_{2} Y+b_{2}  $则

  $  \rho_{\xi \eta}=\frac{a_{1} a_{2}}{\left|a_{1} a_{2}\right|} \rho_{X Y} $

**相关系数**是衡量两个随机变量之间线性相关程度的数字特征。

- 若随机变量$  X, Y  $的相关系数$  \rho_{X Y}  $存在,

  1) 若$  \rho_{X Y}=1, P\{Y=\alpha X+\beta\}=1 $中的$  \alpha>0$，称$  X, Y  $正相关

  2)  $\rho_{X Y}=-1 $，则$  \alpha<0  $称$  X, Y  $**负相关**
  2)  $\rho_{X Y}=0$ ，称$  X, Y  $**不相关**


- $\rho_{X Y}=0  $仅说明$  X, Y  $之间**没有线性关系**，但可以有其他**非线性关系**

### 协方差矩阵

设$  n  $维随机变量$  \left(X_{1}, X_{2}, \ldots, X_{n}\right)  $的协方差

$C_{i j}=\operatorname{Cov}\left(X_{i}, X_{j}\right)$


均存在，称矩阵$  C=\left(c_{i j}\right)  $为$  \left(X_{1}, X_{2}, \ldots, X_{n}\right) $的协方差矩阵.

$C=\left[\begin{array}{cccc}
c_{11} & c_{12} & \ldots & c_{1 n} \\
c_{21} & c_{22} & \ldots & c_{2 n} \\
. & . & \ldots & . \\
c_{n 1} & c_{n 2} & \ldots & c_{n n}
\end{array}\right]$

#### 性质

1)  $c_{i i}=D\left(X_{i}\right), \quad i=1,2, \ldots, n $
2)  $c_{i j}=c_{j i}\quad{i, j=1,2, \ldots, n \text {; }} $:，即对称阵
3)  $C  $是非负定矩阵
4)  $c_{i j}^{2} \leq c_{i i} \cdot c_{i j}, \quad i, j=1,2, \ldots, n $

### 矩

设$  X  $为随机变量, 若$  E\left(|X|^{k}\right)<+\infty $，称

$\gamma_{k}=E\left(X^{k}\right) \quad k=1,2,3 \ldots \ldots$

为$  X  $的$  k  $阶原点矩。

称$  \alpha_{k}=E\left(|X|^{k}\right), k=1,2,3 \ldots . . $为$  X  $的$  k  $阶绝对原点矩。

设$  X  $为随机变量，若$  E\left[|X-E(X)|^{k}\right]   <+\infty $，称

$\mu_{k}=E\left\{[X-E(X)]^{k}\right\} k=1,2,3 \ldots \ldots$


为$  X $的$  k  $阶中心矩。

称$  \beta_{k}=E\left[|X-E(X)|^{k}\right] \quad k=1,2,3 \ldots \ldots  $为$  X  $的$  k $阶绝对中心矩。

注意到$  \mu_{2}=D(X), \gamma_{1}=E(X), \gamma_{2}=E\left(X^{2}\right) $

$\mu_{2}=\gamma_{2}-\gamma_{1}^{2}$


更一般的, 因$  \mu_{1}=0 $, 可得$  \gamma_{k}  $与$  \mu_{k}  $的关系：

$\begin{aligned}
\gamma_{k}=E\left(X^{k}\right) & =E\left\{[X-E(X)+E(X)]^{k}\right\} \\
& =E\left\{\left[\left(X-\gamma_{1}\right)+\gamma_{1}\right]^{k}\right\}\\&=\sum_{i=0}^{k} C_{k}^{i} \gamma_{1}^{i} E\left[\left(X-\gamma_{1}\right)^{k-i}\right] \\
&=\sum_{i=0}^{k} C_{k}^{i} \gamma_{1}^{i} \mu_{k-i}
\end{aligned}$

同理可得

$\mu_{k}=\sum_{i=0}^{k}(-1)^{k-i} C_{k}^{i} \gamma_{1}^{k-i} \gamma_{i}$

**随机变量的矩是数。**

# 🎆第五章 大数定律与中心极限定理

## 大数定律

### 概率不等式

#### 马尔可科夫（Markov）不等式

设随机变量$  Y  $的$  k  $阶绝对原点矩$  E\left\{|Y|^{k}\right\}<   +\infty $，则对于任意的$  \varepsilon>0 $，有

$P\{|Y| \geq \varepsilon\} \leq \frac{E\left\{|Y|^{k}\right\}}{\varepsilon^{k}}, \quad k=1,2, \cdots$

#### 切比雪夫（Chebyshev）不等式

对马尔可科夫不等式特别取$  k=2 $，令$  Y=   X-E(X), E\left\{|Y|^{2}\right\}=D(X)  $存在，有切比雪夫不等式成立.

设随机变量$  X  $的数学期望$  E(X)  $和方差$  D(X) $都存在，则对于任意的$  \varepsilon>0$ ，有

$\begin{array}{c}
P\{|X-E(X)| \geq \varepsilon\} \leq \frac{D(X)}{\varepsilon^{2}} \\
\text { 或者 } \quad P\{|X-E(X)|<\varepsilon\} \geq 1-\frac{D(X)}{\varepsilon^{2}} .
\end{array}$

### 大数定律

#### 依概率收敛

设$  X_{n},~~n=1,2 \ldots  $是一个随机变量序列，$  X  $是一个随机变量或常数，若对于任意的$  \varepsilon>0$，有

$\lim _{n \rightarrow \infty} P\left\{\left|X_{n}-X\right| \geq \varepsilon\right\}=0$

或者

$  \lim _{n \rightarrow \infty} P\left\{\left|X_{n}-X\right|<\varepsilon\right\}=1 $

称随机变量序列$  \left\{X_{n}\right\}  $依概率收敛于$  X $，记为

$X_{n} \stackrel{P}{\longrightarrow} X$

或者$\lim _{n \rightarrow \infty} X_{n}=X,(P)$

> - 在定义中，随机变量$  X  $也可以是常数$  a$，称随机变量序列$  \left\{X_{n}\right\}  $依概率收敛于常数$  a$ 
>
> - 随机变量序列依概率收敛不同于微积分中数列或函数列的收敛性.

随机变量序列$  \left\{X_{n}\right\}  $依概率收敛于$  X  $，指当$  n  $足够大时，有足够大的概率保证$  X_{n}  $任意接近于$  X $，但$  X_{n}  $仍然有可能与$  X  $相差很大。

#### 大数定律的定义

设$  X_{n}, n=1,2 \ldots  $是随机变量序列，其数学期望都存在，若对于任意的$  \varepsilon>0 $, 有

$\lim _{n \rightarrow \infty} P\left\{\left|\frac{1}{n} \sum_{i=1}^{n} X_{i}-\frac{1}{n} \sum_{i=1}^{n} E\left(X_{i}\right)\right|<\varepsilon\right\}=1$


称随机变量序列$  \left\{X_{n}\right\}  $服从大数定律。

服从大数定律的概率意义:  $\left\{X_{k}\right\}, k=1,2 \ldots $的前$  n  $项算术平均将紧密地聚集在其数学期望的附近。

### 切比雪夫大数定律

设$ X_{k}, k=1,2 \ldots  $是相互独立的随机变量序列，其数学期望和方差都存在，且存在常数$  C$，使得

$D\left(X_{n}\right)<C, k=1,2, \ldots$

则随机变量序列$  \left\{X_{k}\right\}, k=1,2 \ldots  $服从大数定律。

#### 独立同分布大数定律

设$  X_{k}, k=1,2 \ldots  $是相互独立且同分布的随机变量序列，且

$  E\left(X_{k}\right)=\mu, D\left(X_{k}\right)=\sigma^{2}, k=   1,2, \ldots  $

则$  \left\{X_{k}\right\}, k=1,2 \ldots  $服从大数定律，即对任意的$  \varepsilon>0 $，有

$\lim _{n \rightarrow \infty} P\left\{\left|\frac{1}{n} \sum_{k=1}^{n} X_{k}-\mu\right|<\varepsilon\right\}=1$

#### 贝努里大数定律

设$  \frac{m}{n} $是$  n  $次重复独立试验中事件  A  发生的频率，$  p $是事件$  A  $在每次试验中发生的概率，则对任意的$  \forall \varepsilon>0 $，有

$\lim _{n \rightarrow \infty} P\left\{\left|\frac{m}{n}-p\right|<\varepsilon\right\}=1$

小概率事件定理：概率很小的事件，在一次试验中几乎是不可能发生的，从而在实际中可看成不可能事件。

#### 辛钦大数定律

设$  X_{k}, k=1,2 \ldots  $是相互独立同分布的随机变量序列，若$  X_{k}  $的数学期望存在，则$  \left\{X_{k}\right\}  $服从大数定律。

## 中心极限定理

设随机变量$  X, X_{1}, X_{2}, \ldots  $的分布函数分别为$  F(x), F_{1}(x), F_{2}(x), \ldots$ ，若极限式

$\lim _{n \rightarrow \infty} F_{n}(x)=F(x)$

在$  F(x)  $的每一个连续点上都成立，称随机变量序列$  \left\{X_{k}\right\}, k=1,2, \ldots  $依分布收敛于$  X $。

记为$X_n\xrightarrow{L} X$

### 中心极限定理

中心极限定理设随机变量序列$  \left\{X_{k}\right\} ， k=1,2, \ldots  $相互独立，有有限数学期望和方差.若随机变量序列

$Y_{n}=\frac{\sum_{k=1}^{n} X_{k}-\sum_{k=1}^{n} E\left(X_{k}\right)}{\sqrt{\sum_{k=1}^{n} D\left(X_{k}\right)}},\text{标准化}$


对$  y \in R  $一致地有

$\lim _{n \rightarrow \infty} P\left\{Y_{n}<y\right\}=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{y} e^{-\frac{1}{2} t^{2}} d t=\Phi(y)$


称随机变量序列$  \left\{X_{k}\right\}  $服从中心极限定理。

> 随机变量序列$  \left\{X_{k}\right\}  $服从中心极限定理，指其前$  n  $项和$ \sum_{k=1}^{n} X_{k}  $的标准化随机变量依分布收敛于标准正态分布随机变量$  X $。

（**概率的近似计算公式**）若随机变量序列$  \left\{X_{k}\right\}, k=1,2, \ldots  $服从中心极限定理，有

$\frac{\sum_{k=1}^{n} X_{k}-\sum_{k=1}^{n} E\left(X_{k}\right)}{\sqrt{\sum_{k=1}^{n} D\left(X_{k}\right)}} \xrightarrow{L} X \sim N(0,1),as~~n\rightarrow \infty$

故当$  n  $足够大时，可以认为

$\frac{\sum_{k=1}^{n} X_{k}-\sum_{k=1}^{n} E\left(X_{k}\right)}{\sqrt{\sum_{k=1}^{n} D\left(X_{k}\right)}} \sim N(0,1)$


近似成立，或

$\sum_{k=1}^{n} X_{k} \sim N\left(\sum_{k=1}^{n} E\left(X_{k}\right), \sum_{k=1}^{n} D\left(X_{k}\right)\right)$


近似成立。

#### 林格伯格-列维定理、独立同分布极限定理

设$  \left\{X_{k}\right\}, k=1,2 \ldots  $为相互独立，具有相同分布的随机变量序列，且$  E\left(X_{k}\right)=\mu, D\left(X_{k}\right)=\sigma^{2} $，则$  \left\{X_{k}\right\}  $满足中心极限定理，即有

$\lim _{n \rightarrow \infty} P\left\{\frac{\sum_{k=1}^{n} X_{k}-n \mu}{\sqrt{n} \sigma} \leq x\right\}=\Phi(x)$

# 🎇第六章 数理统计的基本概念

## 总体、样本与统计量

- 总体：研究对象的单位元素所组成的集合
- 个体：组成总体的每个单位元素
- 样本：按照**一定的规则**从总体中抽取的一部分个体。
- 抽样：抽取样本的过程
- 样本容量：样本中个体的数目n

将第$  i  $个个体的对应指标记为$  X_{i}, i=1,2 ,  \ldots, n$，构成的随机向量$  \left(X_{1}, X_{2}, \cdots, X_{n}\right)  $称为样本。

样本是一组随机变量，其具体试验（观察）数值记为:  $x_{1}, x_{2}, \cdots, x_{n} $，称为样本观测值，简称样本值。

为使样本具有代表性，抽样应满足：

- $X_{i}  $与总体同分布
- $X_{1}, X_{2}, \cdots, X_{n}  $相互独立

设$  X_{1}, X_{2}, \cdots, X_{n}  $是来自总体$  X $的样本，如果**相互独立**且每个分量与总体同分布，称其为**简单随机样本**，简称样本。

若总体$  X  $的分布函数为$  F(x) $，则样本$  X_{1} ,  X_{2}, \cdots, X_{n}  $的联合分布函数为

$\begin{aligned}
F\left(x_{1}, x_{2}, \cdots, x_{n}\right) & =P\left\{X_{1} \leq x_{1}, X_{2} \leq x_{2}, \cdots, X_{n} \leq x_{n}\right\} \\
& =\prod_{k=1}^{n} F_{X_{k}}\left(x_{k}\right)
\end{aligned}$

#### 统计量

设$  X_{1}, X_{2}, \cdots, X_{n}  $是总体$ X  $的样本，$  T  $为$  n  $元实值函数，若样本的函数

$T=T\left(X_{1}, X_{2}, \cdots, X_{n}\right)$

是随机变量且不含未知参数，称$  T  $为**统计量**。

对相应的样本值$  \left(x_{1}, x_{2}, \ldots, x_{n}\right) $，称$ t=T\left(x_{1}, x_{2}, \ldots, x_{n}\right) $

为统计量的**统计值**。

常见统计量

- 样本均值：$\bar{X}=\frac{1}{n} \sum_{i=1}^{n} X_{i}$
- 样本方差：$S^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}$
- 样本$k$阶原点矩：$A_{k}=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k}$
- 样本$k$阶中心矩：$M_{k}=\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{k}$

统称为**样本矩**。

$\begin{array}{l}
A_{1}=\bar{X} \\
M_{2}=\frac{n-1}{n} S^{2}=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{2}-\bar{X}^{2}=A_{2}-A_{1}^{2} \\
X, S^{2}, A_{k}, M_{k} \longmapsto x, \mathrm{~s}^{2}, a_{k}, m_{k}
\end{array}$

样本矩与总体矩的区别：

- 样本矩是随机变量
- 总体矩是数值

## 常用统计分布

### 正态分布

$f(x)=\frac{1}{\sqrt{2 \pi}} e^{\frac{-x^{2}}{2}}, x \in R$


上侧分位数$  u_{\alpha}(0<\alpha<1)  $满足

$P\left\{X>u_{\alpha}\right\}=\int_{u_{\alpha}}^{+\infty} f(x) d x=\alpha$

![](https://pic.imgdb.cn/item/658543ddc458853aef5b64a8.jpg)

对正态分布有$\phi(u_\alpha)=1-\alpha$

### $\chi ^2$分布

$f_{\chi^{2}}(x)=\left\{\begin{array}{ll}
\frac{1}{2 \Gamma\left(\frac{n}{2}\right)}\left(\frac{x}{2}\right)^{\frac{n}{2}-1} e^{-\frac{x}{2}}, x>0 \\
0 , x \leq 0
\end{array}\right.$

其中$  \Gamma(\alpha)  $为 Gama函数，称随机变量$  X  $服从自由度为$  n  $的$  \chi^{2}  $分布，记为$  \chi^{2} \sim \chi^{2}(n) $

Gama函数为

$\Gamma(\alpha)=\int_{0}^{+\infty} x^{\alpha-1} e^{-x} d x, \quad(\alpha>0)$


主要性质:

$\Gamma(1)=1, \quad \Gamma\left(\frac{1}{2}\right)=\sqrt{\pi}, \quad \Gamma(\alpha)=(\alpha-1) \Gamma(\alpha-1)$

设$  X_{1}, X_{2}, \ldots, X_{n}  $相互独立且都服从**标准**正态分布，则标准正态随机变量的独立平方和

$\chi^{2}=\sum_{i=1}^{n} X_{i}^{2} \sim \chi^{2}(n)$

即随机变量$  \chi^{2}  $服从自由度为$  n  $的卡方分布。

$ \chi^{2}(n)  $的上侧分位数$  (0<\alpha<1)  $：

$P\left\{\chi^{2}>\chi_{\alpha}^{2}(n)\right\}=\int_{\chi_{\alpha}^{2}(n)}^{+\infty} f_{\chi^{2}}(x) d x=\alpha$

![](https://pic.imgdb.cn/item/658546f5c458853aef67f562.jpg)

#### 性质

- 数字特征

  设$  \chi^{2} \sim \chi^{2}(n)$ , 则有

  $E\left(\chi^{2}\right)=n, \quad D\left(\chi^{2}\right)=2 n$

- $(n-1)S^2/\sigma^2\sim \chi^2(n-1)$

- 可加性

  设$  Y_{1}, Y_{2}  $相互独立，且$  Y_{1} \sim   \chi^{2}\left(n_{1}\right), Y_{2} \sim \chi^{2}\left(n_{2}\right) $，则$  Y_{1}+Y_{2} \sim \chi^{2}\left(n_{1}+n_{2}\right) .$

- 大样本分位数$\chi^2_\alpha(n)$

  当$  n  $足够大（如$  n>45 $）时，有

  $\chi_{\alpha}^{2}(n) \approx n+u_{\alpha} \sqrt{2 n}$


  其中$  u_{\alpha}  $满足$  \Phi\left(u_{\alpha}\right)=1-\alpha $。

### 自由度为$n$的$t$分布$T\sim t(n)$

$f_{T}(x)=\frac{\Gamma\left(\frac{n+1}{2}\right)}{\sqrt{n \pi} \Gamma\left(\frac{n}{2}\right)}\left(1+\frac{x^{2}}{n}\right)^{-\frac{n+1}{2}}, \quad x \in R$

$ t(n) $的上侧分位数$  t_{\alpha}(n)(0<\alpha<1)  $：

$P\left\{T>t_{\alpha}(n)\right\}=\int_{t_{\alpha}(n)}^{+\infty} f_{T}(x) d x=\alpha$

![](https://pic.imgdb.cn/item/6585493fc458853aef719e4c.jpg)

设随机变量$  X, Y  $相互独立，$X \sim   N(0,1), Y \sim \chi^{2}(n)$ ，则

==$T=\frac{X}{\sqrt{Y / n}} \sim t(n)$==


即随机变量$  T  $服从自由度为$  n  $的$  t  $分布。

#### 特点

- 关于纵轴（y轴）对称：$t_{1-\alpha}(n)=-t_{\alpha}(n)$
- $n  $较大时，$\lim _{n \rightarrow \infty} f_{T}(x)=\varphi(x) $

​	$t_{\alpha}(n) \approx u_{\alpha} \quad(n>30)$

### F分布$F\sim F(n_1,n_2)$

$f_{F}(x)=\left\{\begin{array}{cc}
n_{1} \frac{n_{1}}{2} n_{2} \frac{n_{2}}{2} \frac{\Gamma\left(\frac{n_{1}+n_{2}}{2}\right)}{\Gamma\left(\frac{n_{1}}{2}\right) \Gamma\left(\frac{n_{2}}{2}\right)} x^{\frac{n_{1}}{2}-1}\left(n_{1} x+n_{2}\right)^{-\frac{n_{1}+n_{2}}{2}}, x>0 \\
0, & x \leq 0
\end{array}\right.$

称$  X  $服从第一自由度为$  n_{1} $，第二自由度为$  n_{2} $的$  F  $分布。

设随机变量$  X, Y  $相互独立,

$\begin{aligned}
X \sim \chi^{2}\left(n_{1}\right), & Y \sim \chi^{2}\left(n_{2}\right), \quad \text { 则 } \\
& F=\frac{X / n_{1}}{Y / n_{2}} \sim F\left(n_{1}, n_{2}\right)
\end{aligned}$


即随机变量$  F  $服从第一自由度为$  n_{1} $，第二自由度为$  n_{2}  $的$  F  $分布。

上侧分位数$  F_{\alpha}\left(n_{1}, n_{2}\right) \quad(0<\alpha<1)  $：

$P\left\{F>F_{\alpha}\left(n_{1}, n_{2}\right)\right\}=\int_{F_{\alpha}\left(n_{1}, n_{2}\right)}^{+\infty} f_{F}(x) d x=\alpha$

#### 推论

- 若$ \quad F \sim F\left(n_{1}, n_{2}\right) \Rightarrow \frac{1}{F} \sim F\left(n_{2}, n_{1}\right)$
- 若$\quad F \sim F\left(n_{1}, n_{2}\right) \Rightarrow F_{1-\alpha}\left(n_{1}, n_{2}\right)=\frac{1}{F_{\alpha}\left(n_{2}, n_{1}\right)}$

### 抽样分布定理

设$  X_{1}, X_{2}, \ldots, X_{n}  $是正态总体$  X \sim N\left(\mu, \sigma^{2}\right) $的样本，$\bar{X}, S^{2}  $分别是样本均值和样本方差,则

- $\bar{X} $与$  S^{2}  $相互独立
- $  \frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \sim N(0,1) $
- $\frac{n-1}{\sigma^{2}} S^{2} \sim \chi^{2}(n-1) $
- $ \frac{\bar{X}-\mu}{S / \sqrt{n}} \sim t(n-1) $

设正态总体$  X  $与$  Y  $相互独立，$X \sim N\left(\mu_{1}, \sigma_{1}^{2}\right) $，样本为$  X_{1}, X_{2}, \ldots X_{n_{1}} $，样本均值和样本方差为$  \bar{X}, S_{1}^{2}$

$Y \sim N\left(\mu_{2}, \sigma_{2}^{2}\right) $样本为$Y_{1}, \quad Y_{2}, \ldots Y_{n_{2}} $，样本均值和样本方差为$  \bar{Y}, S_{2}^{2} $，有

- $F=\frac{S_{1}^{2} / \sigma_{1}^{2}}{S_{2}^{2} / \sigma_{2}^{2}} \sim F\left(n_{1}-1, n_{2}-1\right)$ 

- 当$  \sigma_{1}^{2}=\sigma_{2}^{2}  $时，

  $T=\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{S_{w} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}} \sim t\left(n_{1}+n_{2}-2\right)$

  其中，$ S_{w}=\sqrt{\frac{\left(n_{1}-1\right) S_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2}}{n_{1}+n_{2}-2}} $

  $  \bar{X}-\bar{Y}  $服从正态分布，$  S_{w}{ }^{2}  $可化为$  \chi^{2} $分布，二者组合而成的统计量应服从$  t  $分布。
