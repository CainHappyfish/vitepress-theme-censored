---
title: 概率论公式整理-3
date: 2023-12-27 11:48:56
tags:
  - 概率论
---

# 🚗第七章 参数估计

参数估计是对已知分布类型的总体，利用样本对其未知参数作出估计

## 参数的点估计

设总体$X $的分布函数$F( x ;θ )$类型已知，$ θ $是未知参数，$θ $的取值范围$Ω $称为参数空间

**点估计思想**：按一定的优化原则建立一个统计量，将其统计值作为参数$θ $的估计值

设总体$  X  $的分布函数$  F(x ; \theta)  $中的参数$  \theta  $未知，$\theta \in \Omega $。由样本$  X_{1} ,  X_{2}, \ldots, X_{n}  $建立统计量$  T\left(X_{1}, X_{2}, \ldots, X_{n}\right) $，若将其统计值

$t=T\left(x_{1}, x_{2}, \ldots, x_{n}\right)$


作为$  \theta  $的估计值，称

$\hat{\theta}=T\left(X_{1}, X_{2} \cdots, X_{n}\right)$


为$  \theta  $的点估计量。

总体X的分布函数中可有多个不同未知参数。

### 矩估计法

矩是最简单的数字特征。

设总体$  X  $的$  k  $阶矩$  E\left(X^{k}\right)  $存在,  $X_{1}, X_{2}, \ldots, X_{n} $是总体$  X  $的样本，有

$E\left(A_{k}\right)=E\left(\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k}\right)=\frac{1}{n} \sum_{i=1}^{n} E\left(X_{i}^{k}\right)=E\left(X^{k}\right)$


另一方面，根据辛钦大数定律知

$A_{k}=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k} \stackrel{P}{\rightarrow} E\left(X^{k}\right), \quad \text { as } n \rightarrow \infty$


样本矩在一定程度反映了总体矩的特性。

矩估计法的思想简单直观：**替换原则**
* 用样本矩去替换相应的总体矩
* 用样本矩的函数替换相应的总体矩的同一函数

设总体$  X  $的分布函数

$F\left(x ; \theta_{1}, \theta_{2}, \ldots, \theta_{l}\right)$


中含有  l  个未知参数, 假定  X  的  l  阶原点矩存在,记

$\gamma_{k}\left(\theta_{1}, \theta_{2}, \cdots, \theta_{l}\right)=E\left(X^{k}\right), \quad(k=1,2, \cdots, l)$


由方程组

$\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k}=\hat{\gamma}_{k}\left(\theta_{1}, \theta_{2}, \cdots, \theta_{l}\right), \quad k=1,2, \cdots, l .$


解得$  \hat{\theta}_{k}=\hat{\theta}_{k}\left(X_{1}, X_{2}, \cdots, X_{n}\right), k=1,2, \cdots, l ,称  \hat{\theta}_{k}  为  \theta_{k}  $的**矩法估计量.**

若$  \hat{\theta}  $为$  \theta  $的矩法估计量,  $g(\theta)  $是关于$  \theta  $的连续函数，称$  g(\hat{\theta})  $为$  g(\theta)  $的矩法估计量。

**注意**，样本矩是随机变量，而总体矩是数值。

### 极大似然估计法

**求参数的估计值，使似然函数达到极大值。**

极大似然估计法基本思想：按照最大可能性准则进行推断。

若总体$  X  $的概率密度函数为

$  f(x, \theta)  (  \theta  可以是向量),  X_{1}, X_{2}, \cdots, X_{n}  为来自  X 的一个样本,  n  维随机变量  \left(X_{1}, X_{2}, \cdots, X_{n}\right)  $

的联合概率密度函数记为

$L\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)=\prod_{i=1}^{n} f\left(x_{i} ; \theta\right)$


称为参数$  \theta  $的**似然函数**。

对于**离散型样本**，其似然函数为其联合分布律。

若

$\begin{array}{l} 
L\left(x_{1}, x_{2}, \ldots, x_{n} ; \hat{\theta}_{1}, \hat{\theta}_{2}, \ldots, \hat{\theta}_{l}\right) \\
=\max _{\left(\theta_{1}, \theta_{2}, \ldots, \theta_{l}\right) \in \Omega} L\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta_{1}, \theta_{2}, \ldots, \theta_{l}\right)
\end{array}$


称$  \left(\hat{\theta}_{1}, \hat{\theta}_{2}, \ldots, \hat{\theta}_{l}\right)  为  \left(\theta_{1}, \theta_{2}, \ldots, \theta_{l}\right)  $的极大似然估计值.

相应的估计量  \hat{\theta}_{k}=\hat{\theta}_{k}\left(X_{1}, X_{2}, \ldots, X_{n}\right), k=1,2, \cdots, l 称为参数  \theta_{k}  的极大似然估计量.

> $ \ln x  $是$  x $的严格单增函数,  $\ln L  $与$  L  $有相同的极大值点，一般只需求$  \ln L  $的极大值点

称

$\frac{\partial \ln L\left(\theta_{1}, \theta_{2}, \cdots, \theta_{l}\right)}{\partial \theta_{k}}=0, k=1,2, \cdots, l$

**为似然方程组**

**求极大似然估计量的一般步骤：**

1. 写出似然函数

​	$L\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta_{1}, \theta_{2}, \ldots, \theta_{l}\right)=\prod_{i=1}^{n} f\left(x_{i} ; \theta_{1}, \theta_{2}, \ldots, \theta_{l}\right)$

2. 对似然函数取对数

​	$\ln L=\sum_{i=1}^{n} \ln f\left(x_{i} ; \theta_{1}, \theta_{2}, \ldots, \theta_{l}\right)$

3. 对$  \theta_{j}(j=1, \ldots, l  )$分别求偏导，建立似然方程(组)

​	$\frac{\partial \ln L}{\partial \theta_{j}}=0, \quad(j=1,2, \ldots, l)$

​	解得$  \hat{\theta}_{1}, \ldots, \hat{\theta}_{l}  $分别为$  \theta_{1}, \ldots, \theta_{l}  $的极大似然估计值

4. 写出$  \theta_{1}, \ldots, \theta_{l}  $的极大似然估计量.

## 估计量的优良性准则

三个常用准则：**无偏性、有效性、相合性**

### 无偏性

若参数$  \theta  $的估计量$  \hat{\theta}=T\left(X_{1}, X_{2}, \ldots, X_{n}\right) $对一切$  n  $及$  \theta \in \Omega  $，有

$E\left(\hat{\theta}_{n}\right)=E\left[T\left(X_{1}, X_{2}, \ldots, X_{n}\right)\right]=\theta$


称$  \hat{\theta}_{n}  $为$  \theta  $的无偏估计量。若

$\lim _{n \rightarrow \infty} b_{n}=\lim _{n \rightarrow \infty}\left[E\left(\hat{\theta}_{n}\right)-\theta\right]=0$


则称$  \hat{\theta}_{n}  $为$  \theta  $的渐进无偏估计量.

若$  \theta  $的实函数$  g(\theta)  $的无偏估计量存在，称$  g(\theta)  $是可估计函数。

> 注 当$  \hat{\theta}  $是$  \theta  $的无偏估计量，$g(\hat{\theta})  $不一定是$  g(\theta) $的无偏估计量.

样本均值是总体均值$E(X)$的无偏估计量。样本的$k$阶原点矩是总体的k阶原点矩的无偏估计量.

$ M_{2}=\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}  $不是$  \sigma^{2}  $的无偏估计

$\begin{aligned}
\because M_{2} & =\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}=\frac{n-1}{n} S^{2} \\
& \Rightarrow E\left(M_{2}\right)=\frac{n-1}{n} \sigma^{2}
\end{aligned}$


知$  E(X)=\mu  时, \frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}  $是$  \sigma^{2}  $的无偏估计

### 有效性

希望$  \hat{\theta}  $的取值在$  \theta  $及其附近越密集越好，其方差应尽量小。

设$  \hat{\theta}_{1}\left(X_{1}, X_{2}, \ldots, X_{n}\right)  和  \hat{\theta}_{2}\left(X_{1}, X_{2}, \ldots, X_{n}\right) $都是未知参数$  \theta  $的无偏估计量，若

$D\left(\hat{\theta}_{1}\right) \leq D\left(\hat{\theta}_{2}\right), \quad \forall \theta \in \Omega$


称$  \hat{\theta}_{1}  $比$  \hat{\theta}_{2}  $有效 (优效)。

设$  \hat{\theta}_{0}  $是$  \theta  $的无偏估计，如果对$  \theta  $的任何一个无偏估计量$  \hat{\boldsymbol{\theta}}  $都有

$D\left(\hat{\theta}_{0}\right) \leq D(\hat{\theta}), \quad \theta \in \Omega$


称$  \hat{\theta}  $为$  \theta  $的最小方差无偏估计量。$\bar{X} $和$ S^{2}$分别是$ \mu$和$ \sigma^{2}$的最小方差无偏估计。

### 相合性

设$  \hat{\theta}_{n}=\hat{\theta}\left(X_{1}, X_{2}, \ldots, X_{n}\right)  $是未知参数$  \theta  $的估计量，若对任意的$  \varepsilon>0  $，有

$\lim _{n \rightarrow \infty} P\left\{\left|\hat{\theta}_{n}-\theta\right|<\varepsilon\right\}=1$


则称$  \hat{\theta}  $为$  \theta  $的相合估计量。

- $ \bar{X}  $是$  \mu  $的相合估计量
- $  S^{2}  $和$  M_{2}  $都是$  \sigma^{2}  $的相合估计量
- $ \bar{X}  $和$  S^{2}  $分别是$  \mu  $和$  \sigma^{2}  $的相合、无偏估计 
- $ \bar{X}  $和$  S^{2} $分别是$  \mu  $和$  \sigma^{2}  $的最小方差无偏估计

## 区间估计

设总体的末知参数为$  \theta $，由样本$  X_{1} ， \ldots, X_{n}  $确定两个统计量

$\hat{\theta}_{1}=\hat{\theta}_{1}\left(X_{1}, \ldots, X_{n}\right), \quad \hat{\theta}_{2}=\hat{\theta}_{2}\left(X_{1}, \ldots, X_{n}\right)$


对于给定的实数$  \alpha(0<\alpha<1) $ ，满足

$P\left\{\hat{\theta}_{1}\left(X_{1}, \ldots, X_{n}\right) \leq \theta \leq \hat{\theta}_{2}\left(X_{1}, \ldots, X_{n}\right)\right\}=1-\alpha$

称随机区间$  \left[\hat{\boldsymbol{\theta}}_{1}, \hat{\boldsymbol{\theta}}_{2}\right]  $为$  \theta  $的置信度为$  1-\alpha $的区间估计（置信区间）。

$ 1-\alpha  $又称置信水平或置信概率$  \alpha  $称显著性水平，通常取值为$  0.1,0.05 $。

- 随机区间$  \left[\hat{\theta}_{1}, \hat{\theta}_{2}\right]  $以$  1-\alpha  $的概率包含着待估参数$  \theta $，$1-\alpha$反映区间估计的可靠程度
- 随机区间$  \left[\hat{\theta}_{1}, \hat{\theta}_{2}\right]  $的长度$  \hat{\theta}_{2}-\hat{\theta}_{1}  $是随机变量，反映了区间估计的精确程度

### 置信区间的枢轴变量法

1. 选取待估参数$  \theta  $的估计量；

​	原则：优良性准则
​	常用:  $\bar{X} \rightarrow \mu, \quad S^{2} \rightarrow \sigma^{2} $

2. 建立枢轴变量

​	对选定的$  \theta  $的估计量，构造关于待估参数$  \theta $和样本的函数

​	$W\left(X_{1}, X_{2}, \ldots, X_{n}, \theta\right)$


​	其中$  W  $不含任何其他未知参数.
3. 确定$  W  $的分布

  在一定条件下，$ W  $通常具有经典分布(主要有正态、$  \chi^{2}$ 、$ T $、$ F  $分布)；

4. 根据$  W  $的分布，对置信水平$  1-\alpha  $查上侧分位数, 使

​	$P\left\{w_{1-\alpha / 2} \leq W \leq w_{\alpha / 2}\right\}=1-\alpha$

​	或类似的概率式成立。

5. 改写不等式得

   $P\{A \leq \theta \leq B\}=1-\alpha$

   其中$  A $、$ B  $是不含末知参数的统计量（以较大概率包含待估参数）

上面过程的关键是构造枢轴变量$  W $，并以它为轴心，由$  a \leq W \leq b  $旋转出所需不等式

$A \leq \theta \leq B $

### 正态总体（单个正态总体$X\sim N(\mu,\sigma^2)$）的区间估计

- $\mu  $的估计

  - 已知 $\sigma=\sigma_{0}$

    $\begin{array}{c}
    	 U=\frac{\bar{X}-\mu}{\sigma_{0} / \sqrt{n}} \sim N(0,1) \\
    	P\left\{-u_{\alpha / 2} \leq \frac{\bar{X}-\mu}{\sigma_{0} / 		\sqrt{n}} \leq 						u_{\alpha / 2}\right\}=1-\alpha \\
    	{\left[\bar{X}-\frac{\sigma_{0}}{\sqrt{n}} 	\boldsymbol{u}_{\alpha / 2}, \bar{X}+\frac{\sigma_{0}}{\sqrt{n}} 	u_{\alpha / 2}\right]}
    	\end{array}$	

  - $\sigma^2$未知：$T=\frac{\bar{X}-\mu}{S / \sqrt{n}} \sim t(n-1)$

    $\begin{array}{l}
    P\left\{-t_{\alpha / 2}(n-1) \leq \frac{\bar{X}-\mu}{S / \sqrt{n}} \leq t_{\alpha / 2}(n-1)\right\}=1-\alpha \\
    {\left[\bar{X}-t_{\alpha / 2}(n-1) \frac{S}{\sqrt{n}}, \quad \bar{X}+t_{\alpha / 2}(n-1) \frac{S}{\sqrt{n}}\right]}
    \end{array}$

- $\sigma^2$的估计

  $ \sigma^{2}  $的优良估计量为$  S^{2} $，当$  \mu  $未知时，由抽样分布定理可知，应选枢轴变量:

  $\frac{n-1}{\sigma^{2}} S^{2} \sim \chi^{2}(n-1)$


  当$  \mu  $已知时, 应选枢轴变量:

  $\sum_{i=1}^{n}\left(\frac{X_{i}-\mu_{0}}{\sigma}\right)^{2}=\frac{1}{\sigma^{2}} \sum_{i=1}^{n}\left(X_{i}-\mu_{0}\right)^{2} \sim \chi^{2}(n)$

  - 已知$\mu_0$

    $\begin{array}{c}
    \chi^{2}=\sum_{i=1}^{n}\left(\frac{X_{i}-\mu_{0}}{\sigma}\right)^{2}=\frac{1}{\sigma^{2}} \sum_{i=1}^{n}\left(X_{i}-\mu_{0}\right)^{2} \sim \chi^{2}(n) \\
    P\left\{\chi_{1-\alpha / 2}^{2}(n) \leq \frac{1}{\sigma^{2}} \sum_{i=1}^{n}\left(X_{i}-\mu_{0}\right)^{2} \leq \chi_{\alpha / 2}^{2}(n)\right\}=1-\alpha \\
    {\left[\frac{\sum_{i=1}^{n}\left(X_{i}-\mu_{0}\right)^{2}}{\chi_{\alpha / 2}^{2}(n)}, \quad \frac{\sum_{i=1}^{n}\left(X_{i}-\mu_{0}\right)^{2}}{\chi_{1-\alpha / 2}^{2}(n)}\right]}
    \end{array}$

  - 未知$\mu$：$\chi^{2}=\frac{n-1}{\sigma^{2}} S^{2} \sim \chi^{2}(n-1)$

    $\begin{array}{c}
    P\left\{\chi_{1-\alpha / 2}^{2}(n-1) \leq \frac{n-1}{\sigma^{2}} S^{2} \leq \chi_{\alpha / 2}^{2}(n-1)\right\}=1-\alpha \\
    {\left[(n-1) S^{2} / \chi_{\alpha / 2}^{2}(n-1),(n-1) S^{2} / \chi_{1-\alpha / 2}^{2}(n-1)\right]}
    \end{array}$

### 两个正态总体

$ X \sim N\left(\mu_{1}, \sigma_{1}^{2}\right), Y \sim N\left(\mu_{2}, \sigma_{2}^{2}\right)$，$X  $与$  Y  $相互独立
- $\mu_{1}-\mu_{2}  $的估计

  - 已知$  \sigma_{1}{ }^{2}  $和$  \sigma_{2}{ }^{2} $

    枢轴变量取

    $U=\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}} \sim N(\mathbf{0}, \mathbf{1})$

    $\begin{array}{c}
    P\left\{-u_{\frac{\alpha}{2}} \leq \frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}} \leq u_{\frac{\alpha}{2}}\right\}=1-\alpha \\
    {\left[\bar{X}-\bar{Y}-u_{\frac{\alpha}{2}} \sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}, \quad \bar{X}-\bar{Y}+u_{\frac{\alpha}{2}} \sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}\right]}
    \end{array}$

  - $\sigma_1^2$和$\sigma_2^2$未知，但$\sigma_1^2=\sigma_2^2=\sigma^2$

    $T=\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{S_{w} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}} \sim t\left(n_{1}+n_{2}-2\right)$

    $\begin{aligned}
    {\left[\bar{X}-\bar{Y}-t_{\frac{\alpha}{2}}\left(n_{1}+n_{2}-2\right) S_{\mathrm{w}} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}\right.}, \\
    \left.\bar{X}-\bar{Y}+t_{\frac{\alpha}{2}}\left(n_{1}+n_{2}-2\right) S_{\mathrm{w}} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}\right]
    \end{aligned}$

  - 当$n_1=n_2$时

    $\begin{array}{c}
    \text { 记 } Z_{i}=X_{i}-Y_{i}, \quad i=1,2, \cdots, n ; \\
    \text { 则 } \quad \bar{Z}=\frac{1}{n} \sum_{i=1}^{n} Z_{i}=\bar{X}-\bar{Y}, \\
    S_{Z}^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(Z_{i}-\bar{Z}\right)^{2}
    \end{array}$

    因$  Z_{1}, Z_{2}, \cdots, Z_{n}  $相互独立，且

    $Z_{i} \sim N\left(\mu_{1}-\mu_{2}, 2 \sigma^{2}\right)$


    根据抽样定理知，可选枢轴变量

    $T=\frac{\bar{Z}-\left(\mu_{1}-\mu_{2}\right)}{S_{Z} / \sqrt{n}} \sim t(n-1)$

- $\frac{\sigma_{2}^{2}}{\sigma_{1}^{2}}$的区间估计

  - 未知$\mu_1,\mu_2$

    $\begin{array}{l}
    F=\frac{S_{1}^{2} / \sigma_{1}^{2}}{S_{2}^{2} / \sigma_{2}^{2}}=\frac{\sigma_{2}^{2}}{\sigma_{1}^{2}} \cdot \frac{S_{1}^{2}}{S_{2}^{2}} \sim F\left(n_{1}-1, n_{2}-1\right) \\
    P\left\{F_{1-\frac{\alpha}{2}}\left(n_{1}-1, n_{2}-1\right) \leq \frac{\sigma_{2}^{2}}{\sigma_{1}^{2}} \cdot \frac{S_{1}^{2}}{S_{2}^{2}} \leq F_{\frac{\alpha}{2}}\left(n_{1}-1, n_{2}-1\right)\right\}=1-\alpha \\
    {\left[\frac{S_{2}^{2}}{S_{1}^{2}} \cdot F_{1-\frac{\alpha}{2}}\left(n_{1}-1, n_{2}-1\right), \frac{S_{2}^{2}}{S_{1}^{2}} \cdot F_{\frac{\alpha}{2}}\left(n_{1}-1, n_{2}-1\right)\right]}
    \end{array}$

  - 已知$\mu_1,\mu_2$

    $F=\frac{\frac{1}{n_{1}}}{\frac{1}{n_{2}}} \cdot \frac{\sum_{i=1}^{n_{1}}\left(\frac{X_{i}-\mu_{1}}{\sigma_{1}}\right)^{2}}{\sum_{j=1}^{n_{2}}\left(\frac{Y_{j}-\mu_{2}}{\sigma_{2}}\right)^{2}} \sim F\left(n_{1}, n_{2}\right)$

# 🚓第八章 假设检验

## 假设检验的基本思想与步骤

假设检验基本思想：提出统计假设, 根据小概率事件原理对其进行检验。

### 基本概念

- 参数与分布的假设检验

  - 关于总体参数的假设检验，如$H_0=\mu=\mu_0$
  - 关于总体分布的假设检验，如$H_{0}: F(x)=\Psi\left(x ; \mu, \sigma^{2}\right)$

- 原假设与备择假设

  根据问题的需要提出的一对对立的假设，记$  \mathrm{H}_{0}  $为原假设或零假设

  与原假设$  H_{0}$ 相对立的假设称为备选假设，记为$  H_{1} $

  相对于原假设, 可考虑不同的备选假设, 如

  $\begin{array}{l}
  H_{0}: \mu=\mu_{0}, \quad H_{1}: \mu \neq \mu_{0} ; \\
  H_{0}: \mu \leq \mu_{0}, \quad H_{1}: \mu>\mu_{0} ; \\
  H_{0}: \mu \geq \mu_{0}, \quad H_{1}: \mu<\mu_{0} ;
  \end{array}$

- 检验统计量

  用做检验统计推断的统计量

- 假设检验的接受域和拒绝域

  根据假设检验目的， 由样本去推断是否接受原假设$H_0$

  接受域：使$  H_{0}  $得以接受的检验统计量取值的区域$  A $

  否定域：使$  H_{0}  $被否定的检验统计量取值的区域$  R $

### 假设检验的基本步骤

- 提出原假设

  根据实际问题提出原假设$  H_{0}  $和备选假设$  H_{1}  $

- 建立检验统计量

  寻找参数的一个良好估计量，据此建立一个不带任何未知参数的统计量$  U  $作为检验统计量，并在$  H_{0}  $成立的条件下，确定$  U  $的分布(或近似分布)

- 确定$H_0$的否定域

  根据实际问题选定显著性水平$  \alpha  $，依据检验统计量的分布与$  H_{0}  $的内容，确定$  H_{0}  $的否定域

- 对$H_0$作判断

  根据样本值算出检验统计量的统计值$  u  $，判断$  u  $是否落在拒绝域，以确定拒绝或接受$  H_{0} $

对原假设$  H_{0}  $做出判断，称为对$  H_{0}  $做显著性检验，$1-  \alpha  $称为置信水平。

> - 对不同的显著性水平  \alpha  ，有不同的否定域，从而可能有不同的判断结论
> - 在确定$  H_{0}  $的拒绝域时应遵循有利准则:将检验统计量对$  H_{0}  $有利的取值区域确定为接受域，对$  H_{1}  $成立有利的区域作为拒绝域

### 两类错误

- 假设检验的主要依据是 “小概率事件原理”，而小概率事件并非绝对不发生
- 假设检验方法是依据样本去推断总体，样本只是总体的一个局部，不能完全反映整体特性

第一类错误(弃真)：在$  H_{0}  $成立的情况下，错误地否定了$  H_{0}  $

第二类错误(纳伪)：在$  H_{0}  $不成立的情况下错误地接受了$  H_{0} $

减小一类错误，必然使另一错误增大。

## 正态总体的参数检验

### 均值$\mu$的检验

#### U检验法

- 单样本U检验法

  $ X_{1}, \ldots, X_{\mathrm{n}}  $是从正态总体$  N\left(\mu, \sigma_{0}^{2}\right)  $中抽取的简单随机样本

  已知$  \sigma_0^{2} $，检验

  $H_{0}: \mu=\mu_{0}, \quad H_{1}: \mu \neq \mu_{0}$

  原假设成立时，$U=\frac{\bar{X}-\mu_{0}}{\sigma_{0} / \sqrt{n}} \sim N(\mathbf{0}, 1) $

  拒绝域为：$|\boldsymbol{u}|>\boldsymbol{u}_{\frac{\alpha}{2}}$

- 双样本U检验法

  $X_{1}, X_{2}, \cdots, X_{n_{1}}  $来自正态总体$  N\left(\mu 1, \sigma 1^{2}\right)   $

  $Y_{1}, Y_{2}, \cdots, Y_{n_{2}}  $来自正态总体$  N\left(\mu 2, \sigma_{2}^{2}\right) $

  已知$  \sigma 1^{2}  $与$  \sigma 2^{2}$，检验

  $\begin{array}{l}
  \mathrm{H}_{0}: \mu 1=\mu 2 \quad(\text { 或 } \mu 1-\mu 2=0) \\
  \mathrm{H}_{1}: \mu 1 \neq \mu_{2}
  \end{array}$

  原假设$  \mathrm{H}_{0}  $成立时，

  $\begin{aligned}
  U & =\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}}+\frac{\sigma_{2}^{2}}{n_{2}}} \\
  & =\frac{\bar{X}-\bar{Y}}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}} \sim N(\mathbf{0}, \mathbf{1})
  \end{aligned}$

  拒绝域为$|\mu|>\mu_{\frac \alpha 2}$

**U检验法的要点**

1. 构造服从标准正态分布的统计量U 作为检验统计量
2. 为进行标准化，必须已知总体的方差。

#### t检验法

- 单样本t检验法

  $ X_{1}, \ldots, X_{\mathrm{n}}  $是来自正态总体$  N\left(\mu, \sigma^{2}\right) $的样本，$  \mu, \sigma^{2}  $未知，检验

  $H_{0}: \mu=\mu_{0}, \quad \mathbf{H}_{1}: \mu \neq \mu_{0}$

  原假设成立时，$T=\frac{\bar{X}-\mu_{0}}{S / \sqrt{n}} \sim t(n-1) $
  拒绝域为：$|\boldsymbol{t}|>\boldsymbol{t}_{\frac{\alpha}{2}}(n-1) $

- 双样本t检验法

  $ X_{1}, X_{2}, \cdots, X_{n_{1}}  $来自正态总体$  N\left(\mu 1, \sigma^{2}\right)$

  $   Y_{1}, Y_{2}, \cdots, Y_{n_{2}}  $来自正态总体$  N\left(\mu 2, \sigma^{2}\right) $

  检验：$  \quad H_{0}: \mu_{1}=\mu_{2}, H_{1}: \mu_{1} \neq \mu_{2} $

  未知$  \sigma_{1}^{2}, \sigma_{2}^{2} $，但有$  \sigma_{1}^{2}=\sigma_{2}^{2}=\sigma^{2} $

  原假设成立时，检验统计量

  $T=\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{S_{w} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}}=\frac{\bar{X}-\bar{Y}}{S_{w} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}} \sim t\left(n_{1}+n_{2}-2\right)$

  拒绝域为：$\quad|t|>t_{\frac{\alpha}{2}}\left(n_{1}+n_{2}-2\right) $

  其中

  $\begin{aligned}
  \mathrm{S}_{\mathrm{w}}^{2} & =\frac{1}{n_{1}+n_{2}-2}\left[\left(n_{1}-1\right) S_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2}\right] \\
  & =\frac{1}{n_{1}+n_{2}-2}\left[\sum_{i=1}^{\mathrm{n}_{1}}\left(X_{i}-\overline{\mathrm{X}}\right)^{2}+\sum_{j=1}^{\mathrm{n}_{2}}\left(Y_{j}-\bar{Y}\right)^{2}\right]
  \end{aligned}$

### 方差$\sigma^2$的检验

#### $\chi^2$检验法

$ X_{1}, \ldots, X_{\mathrm{n}}  $是来自正态总体$  N\left(\mu, \sigma^{2}\right)  $的样本，检验

$H_{0}: \sigma^{2}=\sigma_{0}{ }^{2} ; \quad \sigma^{2} \neq \sigma_{0}{ }^{2}$

- 已知$\mu$

  原假设成立时，$ \chi^{2}=\sum_{i=1}^{n}\left(\frac{X_{i}-\mu}{\sigma_{0}}\right)^{2} \sim \chi^{2}(n)$

  拒绝域为：

  $\chi^{2}>\chi_{\frac{\alpha}{2}}^{2}(n) \text { 或 } \chi^{2}<\chi_{1-\frac{\alpha}{2}}^{2}(n)$

- 未知$\mu$

  $ X_{1}, \ldots, X_{n}  $是从正态总体$  N\left(\mu, \sigma^{2}\right)  $中抽取的样本，检验

  $H_{0}: \sigma^{2}=\sigma_{0}{ }^{2} ; \quad \mathrm{H}_{1}: \quad \sigma^{2} \neq \sigma_{0}{ }^{2}$

  原假设成立时，$ \chi^{2}=(n-1) \frac{\mathrm{S}^{2}}{\sigma_{0}{ }^{2}} \sim \chi^{2}(n-1) $

  拒绝域为:

  $\chi^{2}>\chi_{\frac{\alpha}{2}}^{2}(n-1) \text { 或 } \chi^{2}<\chi_{1-\frac{\alpha}{2}}^{2}(n-1)$

#### F检验法

$ X_{1}, \ldots, X_{\mathrm{n}_{1}}  $是从正态总体$  N\left(\mu_{1}, \sigma_{1}^{2}\right)  $中抽取的样本

$ Y_{1}, \ldots, Y_{\mathrm{n}_{2}}  $是从正态总体$  N\left(\mu_{2}, \sigma_{2}{ }^{2}\right)  $中抽取的样本

检验

$H_{0}: \sigma_{1}^{2}=\sigma_{2}^{2} ; \quad H_{1}: \sigma_{1}^{2} \neq \sigma_{2}^{2}$

- 已知$\mu_1,\mu_2$

  原假设成立时，

  $F=\frac{n_{2} \sum_{i=1}^{n_{1}}\left(X_{i}-\mu_{1}\right)^{2}}{n_{1} \sum_{j=1}^{n_{2}}\left(Y_{j}-\mu_{2}\right)^{2}} \sim F\left(n_{1}, n_{2}\right)$

  拒绝域为：

  $f>F_{\frac{\alpha}{2}}\left(n_{1}, n_{2}\right) \text { 或 } f<F_{1-\frac{\alpha}{2}}\left(n_{1}, n_{2}\right)$

- 未知$\mu_1,\mu_2$

  原假设成立时，$ \quad F=\frac{S_{1}^{2} / \sigma_{1}^{2}}{S_{2}^{2} / \sigma_{2}^{2}}=\frac{S_{1}^{2}}{S_{2}^{2}} \sim F\left(n_{1}-1, n_{2}-1\right)$

  拒绝域为：

  $f>F_{\frac{\alpha}{2}}\left(n_{1}-1, n_{2}-1\right) \text { 或 } \quad f<F_{1-\frac{\alpha}{2}}\left(n_{1}-1, n_{2}-1\right)$

# 🚕第九章 回归分析

## 相关关系与回归分析

### 相关关系与回归函数

在现实世界中存在大量的变量, 它们有相互依存、相互制约的关系，一般分为两类：确定性关系与非确定性关系。

将作为考察目标的变量称为因变量（记为$  Y$），而将影响它的各个变量称为自变量或可控变量，记为$\left(X_{1}, X_{2}, \cdots X_{k}\right)$

- 确定性的函数关系

​	用第三章方法可求随机变量函数的分布

- 非确定性的相关关系

  构造某种函数来描述输入和输出之间的非确定关系。

考虑单个因变量$  Y  $与单个自变量$  X  $的情形。在 “$  X=x  $” 时，$  Y $（连续型）的条件数学期望为

$\mu(x)=E(Y \mid X=x)=\int_{-\infty}^{+\infty} y f_{Y \mid X}(y \mid x) d y$

1)  $\mu(x)  $可理解为在 “$  X=x  $” 的条件下，随机变量$  Y  $取值的集中点
1)  方程$  y=\mu(x)  $描述了$  Y  $与$  X  $间非确定性的关系

将可控变量$  X_{1}, X_{2}, \cdots X_{k}  $的取值记为$  x_{1} ,  x_{2,}, \ldots, x_{k} $，若条件数学期望:

$\mu\left(x_{1}, x_{2}, \cdots, x_{k}\right)=E\left(Y \mid X_{1}=x_{1}, X_{2}=x_{2}, \cdots X_{k}=x_{k}\right)$

存在，称$  Y  $与$  X_{1}, X_{2}, \cdots X_{k}  $具有相关关系。相关关系是一种非确定性关系

称

$\mu\left(x_{1}, x_{2}, \cdots, x_{k}\right)=E\left(Y \mid X_{1}=x_{1}, X_{2}=x_{2}, \cdots X_{k}=x_{k}\right)$


为$  Y  $关于$  X_{1}, X_{2}, \cdots X_{k}  $的回归函数，方程

$y=\mu\left(x_{1}, x_{2}, \cdots, x_{k}\right)$

称为$  Y  $对$  X_{1}, X_{2}, \cdots X_{k}  $的回归方程。

>  注 回归函数是确定性的函数
>
> 回归分析是从回归函数出发处理相关关系的方法.

### 回归模型的引进

若$  Y  $关于$  X_{1}, X_{2}, \cdots X_{k}  $的回归函数为

$y=\mu\left(x_{1}, x_{2}, \cdots, x_{k}\right)$

设想：$Y=\mu\left(x_{1}, x_{2}, \cdots, x_{k}\right)+ $随机误差（其它末知的、未考虑的因素以及随机因素的影响所产生）

得数学模型:

$\begin{array}{l}
Y=\mu\left(x_{1}, x_{2}, \cdots, x_{k}\right)+\varepsilon \\
\varepsilon=Y-\mu\left(x_{1}, x_{2}, \cdots, x_{k}\right)
\end{array}$

可视为随机误差，通常要求：

1)  $E(\varepsilon)=0 $
2)  $D(\varepsilon)=E\left(\varepsilon^{2}\right)=\sigma^{2}  $尽可能小.

注意到$  \sigma^{2}=E\left[Y-\mu\left(x_{1}, x_{2}, \cdots, x_{n}\right)\right]^{2}   \sigma^{2}  $是用回归函数近似因变量$  Y  $产生的**均方误差**。

### 回归函数类型的估计确定

本节仅讨论最简单的情形：可控变量$Y $关于单个因变量$X $的回归函数存在$\mu(x)=E(Y \mid X=x)$

为估计回归函数，可依据问题的背景，确定或假定回归函数的形式. 称

$y=\hat{\mu}(x)=S(x)$

为$  Y  $关于$  X  $的经验回归方程。

## 一元回归分析

### 一元线性回归模型

若回归函数是线性函数

$\mu\left(x_{1}, x_{2}, \cdots, x_{k}\right)=b_{0}+b_{1} x_{1}+b_{2} x_{2}+\cdots+b_{k} x_{k}$


其中$  b_{0}, b_{1}, \ldots, b_{\mathrm{k}}  $是未知常数，称为线性回归问题。

若  Y  关于  X  的回归函数为

\mu(x)=E(Y \mid X=x)=a+b x


有一元线性回归模型:

$Y=a+b x+\varepsilon, \quad \varepsilon \sim N\left(0, \sigma^{2}\right)$

其中$  a 、 b 、 \sigma^{2}  $为未知参数，且

$ a  $：回归常数（又称截距）

$ b$：回归系数（又称斜率）

$ \varepsilon  $：随机误差（随机扰动项）

若随机误差$  \varepsilon \sim N\left(0, \sigma^{2}\right) $，称为一元线性正态回归模型。

$ \varepsilon_{i}  $是第$  i  $次观察时的随机误差，有

$ \left\{\begin{array}{l}\text { 1) } E\left(\varepsilon_{i}\right)=0, \quad D\left(\varepsilon_{i}\right)=\sigma^{2}, i=1,2, \ldots, n ; \\ \text { 2) } \varepsilon_{1}, \ldots, \quad \varepsilon_{n} \text { 相互独立. } \quad \end{array}\right. $

称为回归假定。

### 一元线性回归模型的参数估计

$ \left\{\begin{array}{l}\text { 用观察值 }\left(x_{\mathrm{i}}, \mathrm{y}_{\mathrm{j}}\right) a 、 b 、 \sigma^{2} \text { 进行估计. } \\ \text { 对所假定的回归模型进行检验 (回归系数 } \mathrm{b})\end{array}\right. $

对自变量$  X  $的一组值$  x_{1}, x_{2}, \ldots, x_{n}  $做$  n  $次独立试验，得独立观察值$  y_{1}, y_{2}, \ldots, y_{n} $。

记$  y_{i} $的估计值为$  \hat{y}_{i}=\hat{a}+\hat{b} x_{i} $称为回归值。

应选$  a $、$ b  $的估计使离差(误差)平方和：

$Q=\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}=\sum_{i=1}^{n}\left(y_{i}-\hat{a}-\hat{b} x_{i}\right)^{2}$

达最小。

令$Q(a, b)=\sum_{i=1}^{n}\left(y_{i}-a-b x_{i}\right)^{2}$

应用**最小二乘法**，建立方程组

$\left\{\begin{array}{l}
\sum_{i=1}^{n}\left(y_{i}-a-b x_{i}\right)=0 \\
\sum_{i=1}^{n}\left(y_{i}-a-b x_{i}\right) x_{i}=0
\end{array}\right.$

得

$\left\{\begin{array}{l}
\hat{b}=\frac{l_{x y}}{l_{x x}} \\
\hat{a}=\bar{y}-\hat{b} \bar{x}
\end{array}\right.$

其中

$\begin{array}{l}
\bar{x}=\frac{1}{n} \sum_{i=1}^{n} x_{i}, \quad \bar{y}=\frac{1}{n} \sum_{i=1}^{n} y_{i} \\
l_{x y}=\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)=\sum_{i=1}^{n} x_{i} y_{i}-n \bar{x} \bar{y} \\
l_{x x}=\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}=\sum_{i=1}^{n} x_{i}^{2}-n \bar{x}^{2}
\end{array}$

由回归假定

$E\left(\varepsilon_{i}\right)=0, \quad D\left(\varepsilon_{i}\right)=\sigma^{2}, i=1,2, \ldots, n ;$


有$  \sigma^{2}=D(\varepsilon)=E\left(\varepsilon^{2}\right)  $，故

$\frac{1}{n} \sum_{i=1}^{n} \varepsilon_{i}^{2}$

是$  \sigma^{2}  $的矩估计量.

可证明$  \sigma^{2}  $的无偏估计量为

$\begin{gathered}{}
\hat{\sigma}^{2}=\frac{1}{n-2}\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2} \\
\textbf{代入 }\hat{y}_i=\hat{a}+\hat{b}x_i\text{,得} \\
\hat{\sigma}^{2}=\frac{1}{n-2}\sum_{i=1}^{n}(l_{yy}-\hat{b}^{2}l_{xx}) \\
l_{yy}=\sum_{i=1}^{n}(y_{i}-\overline{y})^{2}=\sum_{i=1}^{n}y_{i}^{2}-n\overline{y}^{2} 
\end{gathered}$

